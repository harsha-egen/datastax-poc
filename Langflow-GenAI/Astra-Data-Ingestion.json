{"description": "Language Architect at Work!", "icon_bg_color": null, "updated_at": "2024-10-01T20:09:45+00:00", "webhook": false, "id": "8cdcaea0-3dff-4b49-8f4b-2fd81e9b7ebd", "name": "Astra-Data-Ingestion", "icon": null, "is_component": false, "endpoint_name": null, "data": {"nodes": [{"id": "Directory-jr5lu", "type": "genericNode", "position": {"x": -70.60723739635284, "y": 299.6615755225624}, "data": {"type": "Directory", "node": {"template": {"_type": "Component", "code": {"type": "code", "required": true, "placeholder": "", "list": false, "show": true, "multiline": true, "value": "from typing import List\n\nfrom langflow.base.data.utils import parallel_load_data, parse_text_file_to_data, retrieve_file_paths\nfrom langflow.custom import Component\nfrom langflow.io import BoolInput, IntInput, MessageTextInput\nfrom langflow.schema import Data\nfrom langflow.template import Output\n\n\nclass DirectoryComponent(Component):\n    display_name = \"Directory\"\n    description = \"Recursively load files from a directory.\"\n    icon = \"folder\"\n    name = \"Directory\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"path\",\n            display_name=\"Path\",\n            info=\"Path to the directory to load files from.\",\n        ),\n        MessageTextInput(\n            name=\"types\",\n            display_name=\"Types\",\n            info=\"File types to load. Leave empty to load all types.\",\n            is_list=True,\n        ),\n        IntInput(\n            name=\"depth\",\n            display_name=\"Depth\",\n            info=\"Depth to search for files.\",\n            value=0,\n        ),\n        IntInput(\n            name=\"max_concurrency\",\n            display_name=\"Max Concurrency\",\n            advanced=True,\n            info=\"Maximum concurrency for loading files.\",\n            value=2,\n        ),\n        BoolInput(\n            name=\"load_hidden\",\n            display_name=\"Load Hidden\",\n            advanced=True,\n            info=\"If true, hidden files will be loaded.\",\n        ),\n        BoolInput(\n            name=\"recursive\",\n            display_name=\"Recursive\",\n            advanced=True,\n            info=\"If true, the search will be recursive.\",\n        ),\n        BoolInput(\n            name=\"silent_errors\",\n            display_name=\"Silent Errors\",\n            advanced=True,\n            info=\"If true, errors will not raise an exception.\",\n        ),\n        BoolInput(\n            name=\"use_multithreading\",\n            display_name=\"Use Multithreading\",\n            advanced=True,\n            info=\"If true, multithreading will be used.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"load_directory\"),\n    ]\n\n    def load_directory(self) -> List[Data]:\n        path = self.path\n        types = self.types or []  # self.types is already a list due to is_list=True\n        depth = self.depth\n        max_concurrency = self.max_concurrency\n        load_hidden = self.load_hidden\n        recursive = self.recursive\n        silent_errors = self.silent_errors\n        use_multithreading = self.use_multithreading\n\n        resolved_path = self.resolve_path(path)\n        file_paths = retrieve_file_paths(resolved_path, load_hidden, recursive, depth)\n\n        if types:\n            file_paths = [fp for fp in file_paths if any(fp.endswith(ext) for ext in types)]\n\n        loaded_data = []\n\n        if use_multithreading:\n            loaded_data = parallel_load_data(file_paths, silent_errors, max_concurrency)\n        else:\n            loaded_data = [parse_text_file_to_data(file_path, silent_errors) for file_path in file_paths]\n        loaded_data = list(filter(None, loaded_data))\n        self.status = loaded_data\n        return loaded_data  # type: ignore\n", "fileTypes": [], "file_path": "", "password": false, "name": "code", "advanced": true, "dynamic": true, "info": "", "load_from_db": false, "title_case": false}, "depth": {"trace_as_metadata": true, "list": false, "required": false, "placeholder": "", "show": true, "name": "depth", "value": 0, "display_name": "Depth", "advanced": false, "dynamic": false, "info": "Depth to search for files.", "title_case": false, "type": "int", "_input_type": "IntInput"}, "load_hidden": {"trace_as_metadata": true, "list": false, "required": false, "placeholder": "", "show": true, "name": "load_hidden", "value": false, "display_name": "Load Hidden", "advanced": true, "dynamic": false, "info": "If true, hidden files will be loaded.", "title_case": false, "type": "bool", "_input_type": "BoolInput"}, "max_concurrency": {"trace_as_metadata": true, "list": false, "required": false, "placeholder": "", "show": true, "name": "max_concurrency", "value": 2, "display_name": "Max Concurrency", "advanced": true, "dynamic": false, "info": "Maximum concurrency for loading files.", "title_case": false, "type": "int", "_input_type": "IntInput"}, "path": {"trace_as_input": true, "trace_as_metadata": true, "load_from_db": false, "list": false, "required": false, "placeholder": "", "show": true, "name": "path", "value": "/Users/harshagubbichandrashekar/Desktop/DataStax/Ecclesiastical/Data_Datastax/Liverpool", "display_name": "Path", "advanced": false, "input_types": ["Message"], "dynamic": false, "info": "Path to the directory to load files from.", "title_case": false, "type": "str", "_input_type": "MessageTextInput"}, "recursive": {"trace_as_metadata": true, "list": false, "required": false, "placeholder": "", "show": true, "name": "recursive", "value": false, "display_name": "Recursive", "advanced": true, "dynamic": false, "info": "If true, the search will be recursive.", "title_case": false, "type": "bool", "_input_type": "BoolInput"}, "silent_errors": {"trace_as_metadata": true, "list": false, "required": false, "placeholder": "", "show": true, "name": "silent_errors", "value": false, "display_name": "Silent Errors", "advanced": true, "dynamic": false, "info": "If true, errors will not raise an exception.", "title_case": false, "type": "bool", "_input_type": "BoolInput"}, "types": {"trace_as_input": true, "trace_as_metadata": true, "load_from_db": false, "list": true, "required": false, "placeholder": "", "show": true, "name": "types", "value": "", "display_name": "Types", "advanced": false, "input_types": ["Message"], "dynamic": false, "info": "File types to load. Leave empty to load all types.", "title_case": false, "type": "str", "_input_type": "MessageTextInput"}, "use_multithreading": {"trace_as_metadata": true, "list": false, "required": false, "placeholder": "", "show": true, "name": "use_multithreading", "value": false, "display_name": "Use Multithreading", "advanced": true, "dynamic": false, "info": "If true, multithreading will be used.", "title_case": false, "type": "bool", "_input_type": "BoolInput"}}, "description": "Recursively load files from a directory.", "icon": "folder", "base_classes": ["Data"], "display_name": "Directory", "documentation": "", "custom_fields": {}, "output_types": [], "pinned": false, "conditional_paths": [], "frozen": false, "outputs": [{"types": ["Data"], "selected": "Data", "name": "data", "display_name": "Data", "method": "load_directory", "value": "__UNDEFINED__", "cache": true}], "field_order": ["path", "types", "depth", "max_concurrency", "load_hidden", "recursive", "silent_errors", "use_multithreading"], "beta": false, "edited": false, "lf_version": "1.0.18"}, "id": "Directory-jr5lu"}, "selected": false, "width": 384, "height": 474, "positionAbsolute": {"x": -70.60723739635284, "y": 299.6615755225624}, "dragging": false}, {"id": "AstraDB-xyTk2", "type": "genericNode", "position": {"x": 1120.36489326515, "y": 158.1288517296835}, "data": {"type": "AstraDB", "node": {"template": {"_type": "Component", "embedding": {"trace_as_metadata": true, "list": false, "required": false, "placeholder": "", "show": true, "name": "embedding", "value": "", "display_name": "Embedding or Astra Vectorize", "advanced": false, "input_types": ["Embeddings", "dict"], "dynamic": false, "info": "Allows either an embedding model or an Astra Vectorize configuration.", "title_case": false, "type": "other", "_input_type": "HandleInput"}, "ingest_data": {"trace_as_metadata": true, "list": true, "trace_as_input": true, "required": false, "placeholder": "", "show": true, "name": "ingest_data", "value": "", "display_name": "Ingest Data", "advanced": false, "input_types": ["Data"], "dynamic": false, "info": "", "title_case": false, "type": "other", "_input_type": "DataInput"}, "api_endpoint": {"load_from_db": false, "required": true, "placeholder": "", "show": true, "name": "api_endpoint", "value": "https://8beaaa7b-2639-4142-885e-5435e28f6b16-us-east-2.apps.astra.datastax.com", "display_name": "API Endpoint", "advanced": false, "input_types": ["Message"], "dynamic": false, "info": "API endpoint URL for the Astra DB service.", "title_case": false, "password": true, "type": "str", "_input_type": "SecretStrInput"}, "batch_size": {"trace_as_metadata": true, "list": false, "required": false, "placeholder": "", "show": true, "name": "batch_size", "value": "", "display_name": "Batch Size", "advanced": true, "dynamic": false, "info": "Optional number of data to process in a single batch.", "title_case": false, "type": "int", "_input_type": "IntInput"}, "bulk_delete_concurrency": {"trace_as_metadata": true, "list": false, "required": false, "placeholder": "", "show": true, "name": "bulk_delete_concurrency", "value": "", "display_name": "Bulk Delete Concurrency", "advanced": true, "dynamic": false, "info": "Optional concurrency level for bulk delete operations.", "title_case": false, "type": "int", "_input_type": "IntInput"}, "bulk_insert_batch_concurrency": {"trace_as_metadata": true, "list": false, "required": false, "placeholder": "", "show": true, "name": "bulk_insert_batch_concurrency", "value": "", "display_name": "Bulk Insert Batch Concurrency", "advanced": true, "dynamic": false, "info": "Optional concurrency level for bulk insert operations.", "title_case": false, "type": "int", "_input_type": "IntInput"}, "bulk_insert_overwrite_concurrency": {"trace_as_metadata": true, "list": false, "required": false, "placeholder": "", "show": true, "name": "bulk_insert_overwrite_concurrency", "value": "", "display_name": "Bulk Insert Overwrite Concurrency", "advanced": true, "dynamic": false, "info": "Optional concurrency level for bulk insert operations that overwrite existing data.", "title_case": false, "type": "int", "_input_type": "IntInput"}, "code": {"type": "code", "required": true, "placeholder": "", "list": false, "show": true, "multiline": true, "value": "from loguru import logger\n\nfrom langflow.base.vectorstores.model import LCVectorStoreComponent, check_cached_vector_store\nfrom langflow.helpers import docs_to_data\nfrom langflow.inputs import DictInput, FloatInput\nfrom langflow.io import (\n    BoolInput,\n    DataInput,\n    DropdownInput,\n    HandleInput,\n    IntInput,\n    MultilineInput,\n    SecretStrInput,\n    StrInput,\n)\nfrom langflow.schema import Data\n\n\nclass AstraVectorStoreComponent(LCVectorStoreComponent):\n    display_name: str = \"Astra DB\"\n    description: str = \"Implementation of Vector Store using Astra DB with search capabilities\"\n    documentation: str = \"https://python.langchain.com/docs/integrations/vectorstores/astradb\"\n    name = \"AstraDB\"\n    icon: str = \"AstraDB\"\n\n    inputs = [\n        StrInput(\n            name=\"collection_name\",\n            display_name=\"Collection Name\",\n            info=\"The name of the collection within Astra DB where the vectors will be stored.\",\n            required=True,\n        ),\n        SecretStrInput(\n            name=\"token\",\n            display_name=\"Astra DB Application Token\",\n            info=\"Authentication token for accessing Astra DB.\",\n            value=\"ASTRA_DB_APPLICATION_TOKEN\",\n            required=True,\n        ),\n        SecretStrInput(\n            name=\"api_endpoint\",\n            display_name=\"API Endpoint\",\n            info=\"API endpoint URL for the Astra DB service.\",\n            value=\"ASTRA_DB_API_ENDPOINT\",\n            required=True,\n        ),\n        MultilineInput(\n            name=\"search_input\",\n            display_name=\"Search Input\",\n        ),\n        DataInput(\n            name=\"ingest_data\",\n            display_name=\"Ingest Data\",\n            is_list=True,\n        ),\n        StrInput(\n            name=\"namespace\",\n            display_name=\"Namespace\",\n            info=\"Optional namespace within Astra DB to use for the collection.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"metric\",\n            display_name=\"Metric\",\n            info=\"Optional distance metric for vector comparisons in the vector store.\",\n            options=[\"cosine\", \"dot_product\", \"euclidean\"],\n            advanced=True,\n        ),\n        IntInput(\n            name=\"batch_size\",\n            display_name=\"Batch Size\",\n            info=\"Optional number of data to process in a single batch.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"bulk_insert_batch_concurrency\",\n            display_name=\"Bulk Insert Batch Concurrency\",\n            info=\"Optional concurrency level for bulk insert operations.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"bulk_insert_overwrite_concurrency\",\n            display_name=\"Bulk Insert Overwrite Concurrency\",\n            info=\"Optional concurrency level for bulk insert operations that overwrite existing data.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"bulk_delete_concurrency\",\n            display_name=\"Bulk Delete Concurrency\",\n            info=\"Optional concurrency level for bulk delete operations.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"setup_mode\",\n            display_name=\"Setup Mode\",\n            info=\"Configuration mode for setting up the vector store, with options like 'Sync', 'Async', or 'Off'.\",\n            options=[\"Sync\", \"Async\", \"Off\"],\n            advanced=True,\n            value=\"Sync\",\n        ),\n        BoolInput(\n            name=\"pre_delete_collection\",\n            display_name=\"Pre Delete Collection\",\n            info=\"Boolean flag to determine whether to delete the collection before creating a new one.\",\n            advanced=True,\n        ),\n        StrInput(\n            name=\"metadata_indexing_include\",\n            display_name=\"Metadata Indexing Include\",\n            info=\"Optional list of metadata fields to include in the indexing.\",\n            advanced=True,\n        ),\n        HandleInput(\n            name=\"embedding\",\n            display_name=\"Embedding or Astra Vectorize\",\n            input_types=[\"Embeddings\", \"dict\"],\n            info=\"Allows either an embedding model or an Astra Vectorize configuration.\",  # TODO: This should be optional, but need to refactor langchain-astradb first.\n        ),\n        StrInput(\n            name=\"metadata_indexing_exclude\",\n            display_name=\"Metadata Indexing Exclude\",\n            info=\"Optional list of metadata fields to exclude from the indexing.\",\n            advanced=True,\n        ),\n        StrInput(\n            name=\"collection_indexing_policy\",\n            display_name=\"Collection Indexing Policy\",\n            info=\"Optional dictionary defining the indexing policy for the collection.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"number_of_results\",\n            display_name=\"Number of Results\",\n            info=\"Number of results to return.\",\n            advanced=True,\n            value=4,\n        ),\n        DropdownInput(\n            name=\"search_type\",\n            display_name=\"Search Type\",\n            info=\"Search type to use\",\n            options=[\"Similarity\", \"Similarity with score threshold\", \"MMR (Max Marginal Relevance)\"],\n            value=\"Similarity\",\n            advanced=True,\n        ),\n        FloatInput(\n            name=\"search_score_threshold\",\n            display_name=\"Search Score Threshold\",\n            info=\"Minimum similarity score threshold for search results. (when using 'Similarity with score threshold')\",\n            value=0,\n            advanced=True,\n        ),\n        DictInput(\n            name=\"search_filter\",\n            display_name=\"Search Metadata Filter\",\n            info=\"Optional dictionary of filters to apply to the search query.\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n\n    @check_cached_vector_store\n    def build_vector_store(self):\n        try:\n            from langchain_astradb import AstraDBVectorStore\n            from langchain_astradb.utils.astradb import SetupMode\n        except ImportError:\n            raise ImportError(\n                \"Could not import langchain Astra DB integration package. \"\n                \"Please install it with `pip install langchain-astradb`.\"\n            )\n\n        try:\n            if not self.setup_mode:\n                self.setup_mode = self._inputs[\"setup_mode\"].options[0]\n\n            setup_mode_value = SetupMode[self.setup_mode.upper()]\n        except KeyError:\n            raise ValueError(f\"Invalid setup mode: {self.setup_mode}\")\n\n        if not isinstance(self.embedding, dict):\n            embedding_dict = {\"embedding\": self.embedding}\n        else:\n            from astrapy.info import CollectionVectorServiceOptions\n\n            dict_options = self.embedding.get(\"collection_vector_service_options\", {})\n            dict_options[\"authentication\"] = {\n                k: v for k, v in dict_options.get(\"authentication\", {}).items() if k and v\n            }\n            dict_options[\"parameters\"] = {k: v for k, v in dict_options.get(\"parameters\", {}).items() if k and v}\n            embedding_dict = {\n                \"collection_vector_service_options\": CollectionVectorServiceOptions.from_dict(dict_options)\n            }\n            collection_embedding_api_key = self.embedding.get(\"collection_embedding_api_key\")\n            if collection_embedding_api_key:\n                embedding_dict[\"collection_embedding_api_key\"] = collection_embedding_api_key\n\n        vector_store_kwargs = {\n            **embedding_dict,\n            \"collection_name\": self.collection_name,\n            \"token\": self.token,\n            \"api_endpoint\": self.api_endpoint,\n            \"namespace\": self.namespace or None,\n            \"metric\": self.metric or None,\n            \"batch_size\": self.batch_size or None,\n            \"bulk_insert_batch_concurrency\": self.bulk_insert_batch_concurrency or None,\n            \"bulk_insert_overwrite_concurrency\": self.bulk_insert_overwrite_concurrency or None,\n            \"bulk_delete_concurrency\": self.bulk_delete_concurrency or None,\n            \"setup_mode\": setup_mode_value,\n            \"pre_delete_collection\": self.pre_delete_collection or False,\n        }\n\n        if self.metadata_indexing_include:\n            vector_store_kwargs[\"metadata_indexing_include\"] = self.metadata_indexing_include\n        elif self.metadata_indexing_exclude:\n            vector_store_kwargs[\"metadata_indexing_exclude\"] = self.metadata_indexing_exclude\n        elif self.collection_indexing_policy:\n            vector_store_kwargs[\"collection_indexing_policy\"] = self.collection_indexing_policy\n\n        try:\n            vector_store = AstraDBVectorStore(**vector_store_kwargs)\n        except Exception as e:\n            raise ValueError(f\"Error initializing AstraDBVectorStore: {str(e)}\") from e\n\n        self._add_documents_to_vector_store(vector_store)\n        return vector_store\n\n    def _add_documents_to_vector_store(self, vector_store):\n        documents = []\n        for _input in self.ingest_data or []:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n            else:\n                raise ValueError(\"Vector Store Inputs must be Data objects.\")\n\n        if documents:\n            logger.debug(f\"Adding {len(documents)} documents to the Vector Store.\")\n            try:\n                vector_store.add_documents(documents)\n            except Exception as e:\n                raise ValueError(f\"Error adding documents to AstraDBVectorStore: {str(e)}\") from e\n        else:\n            logger.debug(\"No documents to add to the Vector Store.\")\n\n    def _map_search_type(self):\n        if self.search_type == \"Similarity with score threshold\":\n            return \"similarity_score_threshold\"\n        elif self.search_type == \"MMR (Max Marginal Relevance)\":\n            return \"mmr\"\n        else:\n            return \"similarity\"\n\n    def _build_search_args(self):\n        args = {\n            \"k\": self.number_of_results,\n            \"score_threshold\": self.search_score_threshold,\n        }\n\n        if self.search_filter:\n            clean_filter = {k: v for k, v in self.search_filter.items() if k and v}\n            if len(clean_filter) > 0:\n                args[\"filter\"] = clean_filter\n        return args\n\n    def search_documents(self) -> list[Data]:\n        vector_store = self.build_vector_store()\n\n        logger.debug(f\"Search input: {self.search_input}\")\n        logger.debug(f\"Search type: {self.search_type}\")\n        logger.debug(f\"Number of results: {self.number_of_results}\")\n\n        if self.search_input and isinstance(self.search_input, str) and self.search_input.strip():\n            try:\n                search_type = self._map_search_type()\n                search_args = self._build_search_args()\n\n                docs = vector_store.search(query=self.search_input, search_type=search_type, **search_args)\n            except Exception as e:\n                raise ValueError(f\"Error performing search in AstraDBVectorStore: {str(e)}\") from e\n\n            logger.debug(f\"Retrieved documents: {len(docs)}\")\n\n            data = docs_to_data(docs)\n            logger.debug(f\"Converted documents to data: {len(data)}\")\n            self.status = data\n            return data\n        else:\n            logger.debug(\"No search input provided. Skipping search.\")\n            return []\n\n    def get_retriever_kwargs(self):\n        search_args = self._build_search_args()\n        return {\n            \"search_type\": self._map_search_type(),\n            \"search_kwargs\": search_args,\n        }\n", "fileTypes": [], "file_path": "", "password": false, "name": "code", "advanced": true, "dynamic": true, "info": "", "load_from_db": false, "title_case": false}, "collection_indexing_policy": {"trace_as_metadata": true, "load_from_db": false, "list": false, "required": false, "placeholder": "", "show": true, "name": "collection_indexing_policy", "value": "", "display_name": "Collection Indexing Policy", "advanced": true, "dynamic": false, "info": "Optional dictionary defining the indexing policy for the collection.", "title_case": false, "type": "str", "_input_type": "StrInput"}, "collection_name": {"trace_as_metadata": true, "load_from_db": false, "list": false, "required": true, "placeholder": "", "show": true, "name": "collection_name", "value": "football", "display_name": "Collection Name", "advanced": false, "dynamic": false, "info": "The name of the collection within Astra DB where the vectors will be stored.", "title_case": false, "type": "str", "_input_type": "StrInput"}, "metadata_indexing_exclude": {"trace_as_metadata": true, "load_from_db": false, "list": false, "required": false, "placeholder": "", "show": true, "name": "metadata_indexing_exclude", "value": "", "display_name": "Metadata Indexing Exclude", "advanced": true, "dynamic": false, "info": "Optional list of metadata fields to exclude from the indexing.", "title_case": false, "type": "str", "_input_type": "StrInput"}, "metadata_indexing_include": {"trace_as_metadata": true, "load_from_db": false, "list": false, "required": false, "placeholder": "", "show": true, "name": "metadata_indexing_include", "value": "", "display_name": "Metadata Indexing Include", "advanced": true, "dynamic": false, "info": "Optional list of metadata fields to include in the indexing.", "title_case": false, "type": "str", "_input_type": "StrInput"}, "metric": {"trace_as_metadata": true, "options": ["cosine", "dot_product", "euclidean"], "combobox": false, "required": false, "placeholder": "", "show": true, "name": "metric", "value": "", "display_name": "Metric", "advanced": true, "dynamic": false, "info": "Optional distance metric for vector comparisons in the vector store.", "title_case": false, "type": "str", "_input_type": "DropdownInput"}, "namespace": {"trace_as_metadata": true, "load_from_db": false, "list": false, "required": false, "placeholder": "", "show": true, "name": "namespace", "value": "", "display_name": "Namespace", "advanced": true, "dynamic": false, "info": "Optional namespace within Astra DB to use for the collection.", "title_case": false, "type": "str", "_input_type": "StrInput"}, "number_of_results": {"trace_as_metadata": true, "list": false, "required": false, "placeholder": "", "show": true, "name": "number_of_results", "value": 4, "display_name": "Number of Results", "advanced": true, "dynamic": false, "info": "Number of results to return.", "title_case": false, "type": "int", "_input_type": "IntInput"}, "pre_delete_collection": {"trace_as_metadata": true, "list": false, "required": false, "placeholder": "", "show": true, "name": "pre_delete_collection", "value": false, "display_name": "Pre Delete Collection", "advanced": true, "dynamic": false, "info": "Boolean flag to determine whether to delete the collection before creating a new one.", "title_case": false, "type": "bool", "_input_type": "BoolInput"}, "search_filter": {"trace_as_input": true, "list": true, "required": false, "placeholder": "", "show": true, "name": "search_filter", "value": {}, "display_name": "Search Metadata Filter", "advanced": true, "dynamic": false, "info": "Optional dictionary of filters to apply to the search query.", "title_case": false, "type": "dict", "_input_type": "DictInput"}, "search_input": {"trace_as_input": true, "multiline": true, "trace_as_metadata": true, "load_from_db": false, "list": false, "required": false, "placeholder": "", "show": true, "name": "search_input", "value": "", "display_name": "Search Input", "advanced": false, "input_types": ["Message"], "dynamic": false, "info": "", "title_case": false, "type": "str", "_input_type": "MultilineInput"}, "search_score_threshold": {"trace_as_metadata": true, "list": false, "required": false, "placeholder": "", "show": true, "name": "search_score_threshold", "value": 0, "display_name": "Search Score Threshold", "advanced": true, "dynamic": false, "info": "Minimum similarity score threshold for search results. (when using 'Similarity with score threshold')", "title_case": false, "type": "float", "_input_type": "FloatInput"}, "search_type": {"trace_as_metadata": true, "options": ["Similarity", "Similarity with score threshold", "MMR (Max Marginal Relevance)"], "combobox": false, "required": false, "placeholder": "", "show": true, "name": "search_type", "value": "Similarity", "display_name": "Search Type", "advanced": true, "dynamic": false, "info": "Search type to use", "title_case": false, "type": "str", "_input_type": "DropdownInput"}, "setup_mode": {"trace_as_metadata": true, "options": ["Sync", "Async", "Off"], "combobox": false, "required": false, "placeholder": "", "show": true, "name": "setup_mode", "value": "Sync", "display_name": "Setup Mode", "advanced": true, "dynamic": false, "info": "Configuration mode for setting up the vector store, with options like 'Sync', 'Async', or 'Off'.", "title_case": false, "type": "str", "_input_type": "DropdownInput"}, "token": {"load_from_db": false, "required": true, "placeholder": "", "show": true, "name": "token", "value": "AstraCS:NtRWeYNlnrkMBBIBolUCWxEd:85bb27f3a9b0f9e646683982a81cf35d3d9391ccbe3907a596dafa715b800ff5", "display_name": "Astra DB Application Token", "advanced": false, "input_types": ["Message"], "dynamic": false, "info": "Authentication token for accessing Astra DB.", "title_case": false, "password": true, "type": "str", "_input_type": "SecretStrInput"}}, "description": "Implementation of Vector Store using Astra DB with search capabilities", "icon": "AstraDB", "base_classes": ["Data", "Retriever", "VectorStore"], "display_name": "Astra DB", "documentation": "https://python.langchain.com/docs/integrations/vectorstores/astradb", "custom_fields": {}, "output_types": [], "pinned": false, "conditional_paths": [], "frozen": false, "outputs": [{"types": ["Retriever"], "selected": "Retriever", "name": "base_retriever", "display_name": "Retriever", "method": "build_base_retriever", "value": "__UNDEFINED__", "cache": true}, {"types": ["Data"], "selected": "Data", "name": "search_results", "display_name": "Search Results", "method": "search_documents", "value": "__UNDEFINED__", "cache": true}, {"types": ["VectorStore"], "selected": "VectorStore", "name": "vector_store", "display_name": "Vector Store", "method": "cast_vector_store", "value": "__UNDEFINED__", "cache": true}], "field_order": ["collection_name", "token", "api_endpoint", "search_input", "ingest_data", "namespace", "metric", "batch_size", "bulk_insert_batch_concurrency", "bulk_insert_overwrite_concurrency", "bulk_delete_concurrency", "setup_mode", "pre_delete_collection", "metadata_indexing_include", "embedding", "metadata_indexing_exclude", "collection_indexing_policy", "number_of_results", "search_type", "search_score_threshold", "search_filter"], "beta": false, "edited": false}, "id": "AstraDB-xyTk2"}, "selected": false, "width": 384, "height": 774, "positionAbsolute": {"x": 1120.36489326515, "y": 158.1288517296835}, "dragging": false}, {"id": "SplitText-zvEyZ", "type": "genericNode", "position": {"x": 522.8736240262755, "y": 7.192797690281878}, "data": {"type": "SplitText", "node": {"template": {"_type": "Component", "data_inputs": {"trace_as_metadata": true, "list": true, "required": false, "placeholder": "", "show": true, "name": "data_inputs", "value": "", "display_name": "Data Inputs", "advanced": false, "input_types": ["Data"], "dynamic": false, "info": "The data to split.", "title_case": false, "type": "other", "_input_type": "HandleInput"}, "chunk_overlap": {"trace_as_metadata": true, "list": false, "required": false, "placeholder": "", "show": true, "name": "chunk_overlap", "value": 200, "display_name": "Chunk Overlap", "advanced": false, "dynamic": false, "info": "Number of characters to overlap between chunks.", "title_case": false, "type": "int", "_input_type": "IntInput"}, "chunk_size": {"trace_as_metadata": true, "list": false, "required": false, "placeholder": "", "show": true, "name": "chunk_size", "value": 1000, "display_name": "Chunk Size", "advanced": false, "dynamic": false, "info": "The maximum number of characters in each chunk.", "title_case": false, "type": "int", "_input_type": "IntInput"}, "code": {"type": "code", "required": true, "placeholder": "", "list": false, "show": true, "multiline": true, "value": "from typing import List\n\nfrom langchain_text_splitters import CharacterTextSplitter\n\nfrom langflow.custom import Component\nfrom langflow.io import HandleInput, IntInput, MessageTextInput, Output\nfrom langflow.schema import Data\nfrom langflow.utils.util import unescape_string\n\n\nclass SplitTextComponent(Component):\n    display_name: str = \"Split Text\"\n    description: str = \"Split text into chunks based on specified criteria.\"\n    icon = \"scissors-line-dashed\"\n    name = \"SplitText\"\n\n    inputs = [\n        HandleInput(\n            name=\"data_inputs\",\n            display_name=\"Data Inputs\",\n            info=\"The data to split.\",\n            input_types=[\"Data\"],\n            is_list=True,\n        ),\n        IntInput(\n            name=\"chunk_overlap\",\n            display_name=\"Chunk Overlap\",\n            info=\"Number of characters to overlap between chunks.\",\n            value=200,\n        ),\n        IntInput(\n            name=\"chunk_size\",\n            display_name=\"Chunk Size\",\n            info=\"The maximum number of characters in each chunk.\",\n            value=1000,\n        ),\n        MessageTextInput(\n            name=\"separator\",\n            display_name=\"Separator\",\n            info=\"The character to split on. Defaults to newline.\",\n            value=\"\\n\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Chunks\", name=\"chunks\", method=\"split_text\"),\n    ]\n\n    def _docs_to_data(self, docs):\n        data = []\n        for doc in docs:\n            data.append(Data(text=doc.page_content, data=doc.metadata))\n        return data\n\n    def split_text(self) -> List[Data]:\n        separator = unescape_string(self.separator)\n\n        documents = []\n        for _input in self.data_inputs:\n            if isinstance(_input, Data):\n                documents.append(_input.to_lc_document())\n\n        splitter = CharacterTextSplitter(\n            chunk_overlap=self.chunk_overlap,\n            chunk_size=self.chunk_size,\n            separator=separator,\n        )\n        docs = splitter.split_documents(documents)\n        data = self._docs_to_data(docs)\n        self.status = data\n        return data\n", "fileTypes": [], "file_path": "", "password": false, "name": "code", "advanced": true, "dynamic": true, "info": "", "load_from_db": false, "title_case": false}, "separator": {"trace_as_input": true, "trace_as_metadata": true, "load_from_db": false, "list": false, "required": false, "placeholder": "", "show": true, "name": "separator", "value": "\n", "display_name": "Separator", "advanced": false, "input_types": ["Message"], "dynamic": false, "info": "The character to split on. Defaults to newline.", "title_case": false, "type": "str", "_input_type": "MessageTextInput"}}, "description": "Split text into chunks based on specified criteria.", "icon": "scissors-line-dashed", "base_classes": ["Data"], "display_name": "Split Text", "documentation": "", "custom_fields": {}, "output_types": [], "pinned": false, "conditional_paths": [], "frozen": false, "outputs": [{"types": ["Data"], "selected": "Data", "name": "chunks", "display_name": "Chunks", "method": "split_text", "value": "__UNDEFINED__", "cache": true}], "field_order": ["data_inputs", "chunk_overlap", "chunk_size", "separator"], "beta": false, "edited": false}, "id": "SplitText-zvEyZ"}, "selected": false, "width": 384, "height": 550, "positionAbsolute": {"x": 522.8736240262755, "y": 7.192797690281878}, "dragging": false}, {"id": "OpenAIEmbeddings-iMoBU", "type": "genericNode", "position": {"x": 546.0624433564828, "y": 628.7086167740968}, "data": {"type": "OpenAIEmbeddings", "node": {"template": {"_type": "Component", "chunk_size": {"trace_as_metadata": true, "list": false, "required": false, "placeholder": "", "show": true, "name": "chunk_size", "value": 1000, "display_name": "Chunk Size", "advanced": true, "dynamic": false, "info": "", "title_case": false, "type": "int", "_input_type": "IntInput"}, "client": {"trace_as_input": true, "trace_as_metadata": true, "load_from_db": false, "list": false, "required": false, "placeholder": "", "show": true, "name": "client", "value": "", "display_name": "Client", "advanced": true, "input_types": ["Message"], "dynamic": false, "info": "", "title_case": false, "type": "str", "_input_type": "MessageTextInput"}, "code": {"type": "code", "required": true, "placeholder": "", "list": false, "show": true, "multiline": true, "value": "from langchain_openai.embeddings.base import OpenAIEmbeddings\n\nfrom langflow.base.embeddings.model import LCEmbeddingsModel\nfrom langflow.base.models.openai_constants import OPENAI_EMBEDDING_MODEL_NAMES\nfrom langflow.field_typing import Embeddings\nfrom langflow.io import BoolInput, DictInput, DropdownInput, FloatInput, IntInput, MessageTextInput, SecretStrInput\n\n\nclass OpenAIEmbeddingsComponent(LCEmbeddingsModel):\n    display_name = \"OpenAI Embeddings\"\n    description = \"Generate embeddings using OpenAI models.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIEmbeddings\"\n\n    inputs = [\n        DictInput(\n            name=\"default_headers\",\n            display_name=\"Default Headers\",\n            advanced=True,\n            info=\"Default headers to use for the API request.\",\n        ),\n        DictInput(\n            name=\"default_query\",\n            display_name=\"Default Query\",\n            advanced=True,\n            info=\"Default query parameters to use for the API request.\",\n        ),\n        IntInput(name=\"chunk_size\", display_name=\"Chunk Size\", advanced=True, value=1000),\n        MessageTextInput(name=\"client\", display_name=\"Client\", advanced=True),\n        MessageTextInput(name=\"deployment\", display_name=\"Deployment\", advanced=True),\n        IntInput(name=\"embedding_ctx_length\", display_name=\"Embedding Context Length\", advanced=True, value=1536),\n        IntInput(name=\"max_retries\", display_name=\"Max Retries\", value=3, advanced=True),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            advanced=False,\n            options=OPENAI_EMBEDDING_MODEL_NAMES,\n            value=\"text-embedding-3-small\",\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        SecretStrInput(name=\"openai_api_base\", display_name=\"OpenAI API Base\", advanced=True),\n        SecretStrInput(name=\"openai_api_key\", display_name=\"OpenAI API Key\", value=\"OPENAI_API_KEY\"),\n        SecretStrInput(name=\"openai_api_type\", display_name=\"OpenAI API Type\", advanced=True),\n        MessageTextInput(name=\"openai_api_version\", display_name=\"OpenAI API Version\", advanced=True),\n        MessageTextInput(\n            name=\"openai_organization\",\n            display_name=\"OpenAI Organization\",\n            advanced=True,\n        ),\n        MessageTextInput(name=\"openai_proxy\", display_name=\"OpenAI Proxy\", advanced=True),\n        FloatInput(name=\"request_timeout\", display_name=\"Request Timeout\", advanced=True),\n        BoolInput(name=\"show_progress_bar\", display_name=\"Show Progress Bar\", advanced=True),\n        BoolInput(name=\"skip_empty\", display_name=\"Skip Empty\", advanced=True),\n        MessageTextInput(\n            name=\"tiktoken_model_name\",\n            display_name=\"TikToken Model Name\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"tiktoken_enable\",\n            display_name=\"TikToken Enable\",\n            advanced=True,\n            value=True,\n            info=\"If False, you must have transformers installed.\",\n        ),\n        IntInput(\n            name=\"dimensions\",\n            display_name=\"Dimensions\",\n            info=\"The number of dimensions the resulting output embeddings should have. Only supported by certain models.\",\n            advanced=True,\n        ),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        return OpenAIEmbeddings(\n            tiktoken_enabled=self.tiktoken_enable,\n            default_headers=self.default_headers,\n            default_query=self.default_query,\n            allowed_special=\"all\",\n            disallowed_special=\"all\",\n            chunk_size=self.chunk_size,\n            deployment=self.deployment,\n            embedding_ctx_length=self.embedding_ctx_length,\n            max_retries=self.max_retries,\n            model=self.model,\n            model_kwargs=self.model_kwargs,\n            base_url=self.openai_api_base,\n            api_key=self.openai_api_key,\n            openai_api_type=self.openai_api_type,\n            api_version=self.openai_api_version,\n            organization=self.openai_organization,\n            openai_proxy=self.openai_proxy,\n            timeout=self.request_timeout or None,\n            show_progress_bar=self.show_progress_bar,\n            skip_empty=self.skip_empty,\n            tiktoken_model_name=self.tiktoken_model_name,\n            dimensions=self.dimensions or None,\n        )\n", "fileTypes": [], "file_path": "", "password": false, "name": "code", "advanced": true, "dynamic": true, "info": "", "load_from_db": false, "title_case": false}, "default_headers": {"trace_as_input": true, "list": false, "required": false, "placeholder": "", "show": true, "name": "default_headers", "value": {}, "display_name": "Default Headers", "advanced": true, "dynamic": false, "info": "Default headers to use for the API request.", "title_case": false, "type": "dict", "_input_type": "DictInput"}, "default_query": {"trace_as_input": true, "list": false, "required": false, "placeholder": "", "show": true, "name": "default_query", "value": {}, "display_name": "Default Query", "advanced": true, "dynamic": false, "info": "Default query parameters to use for the API request.", "title_case": false, "type": "dict", "_input_type": "DictInput"}, "deployment": {"trace_as_input": true, "trace_as_metadata": true, "load_from_db": false, "list": false, "required": false, "placeholder": "", "show": true, "name": "deployment", "value": "", "display_name": "Deployment", "advanced": true, "input_types": ["Message"], "dynamic": false, "info": "", "title_case": false, "type": "str", "_input_type": "MessageTextInput"}, "dimensions": {"trace_as_metadata": true, "list": false, "required": false, "placeholder": "", "show": true, "name": "dimensions", "value": "", "display_name": "Dimensions", "advanced": true, "dynamic": false, "info": "The number of dimensions the resulting output embeddings should have. Only supported by certain models.", "title_case": false, "type": "int", "_input_type": "IntInput"}, "embedding_ctx_length": {"trace_as_metadata": true, "list": false, "required": false, "placeholder": "", "show": true, "name": "embedding_ctx_length", "value": 1536, "display_name": "Embedding Context Length", "advanced": true, "dynamic": false, "info": "", "title_case": false, "type": "int", "_input_type": "IntInput"}, "max_retries": {"trace_as_metadata": true, "list": false, "required": false, "placeholder": "", "show": true, "name": "max_retries", "value": 3, "display_name": "Max Retries", "advanced": true, "dynamic": false, "info": "", "title_case": false, "type": "int", "_input_type": "IntInput"}, "model": {"trace_as_metadata": true, "options": ["text-embedding-3-small", "text-embedding-3-large", "text-embedding-ada-002"], "combobox": false, "required": false, "placeholder": "", "show": true, "name": "model", "value": "text-embedding-3-small", "display_name": "Model", "advanced": false, "dynamic": false, "info": "", "title_case": false, "type": "str", "_input_type": "DropdownInput"}, "model_kwargs": {"trace_as_input": true, "list": false, "required": false, "placeholder": "", "show": true, "name": "model_kwargs", "value": {}, "display_name": "Model Kwargs", "advanced": true, "dynamic": false, "info": "", "title_case": false, "type": "dict", "_input_type": "DictInput"}, "openai_api_base": {"load_from_db": false, "required": false, "placeholder": "", "show": true, "name": "openai_api_base", "value": "", "display_name": "OpenAI API Base", "advanced": true, "input_types": ["Message"], "dynamic": false, "info": "", "title_case": false, "password": true, "type": "str", "_input_type": "SecretStrInput"}, "openai_api_key": {"load_from_db": false, "required": false, "placeholder": "", "show": true, "name": "openai_api_key", "value": null, "display_name": "OpenAI API Key", "advanced": false, "input_types": ["Message"], "dynamic": false, "info": "", "title_case": false, "password": true, "type": "str", "_input_type": "SecretStrInput"}, "openai_api_type": {"load_from_db": false, "required": false, "placeholder": "", "show": true, "name": "openai_api_type", "value": "", "display_name": "OpenAI API Type", "advanced": true, "input_types": ["Message"], "dynamic": false, "info": "", "title_case": false, "password": true, "type": "str", "_input_type": "SecretStrInput"}, "openai_api_version": {"trace_as_input": true, "trace_as_metadata": true, "load_from_db": false, "list": false, "required": false, "placeholder": "", "show": true, "name": "openai_api_version", "value": "", "display_name": "OpenAI API Version", "advanced": true, "input_types": ["Message"], "dynamic": false, "info": "", "title_case": false, "type": "str", "_input_type": "MessageTextInput"}, "openai_organization": {"trace_as_input": true, "trace_as_metadata": true, "load_from_db": false, "list": false, "required": false, "placeholder": "", "show": true, "name": "openai_organization", "value": "", "display_name": "OpenAI Organization", "advanced": true, "input_types": ["Message"], "dynamic": false, "info": "", "title_case": false, "type": "str", "_input_type": "MessageTextInput"}, "openai_proxy": {"trace_as_input": true, "trace_as_metadata": true, "load_from_db": false, "list": false, "required": false, "placeholder": "", "show": true, "name": "openai_proxy", "value": "", "display_name": "OpenAI Proxy", "advanced": true, "input_types": ["Message"], "dynamic": false, "info": "", "title_case": false, "type": "str", "_input_type": "MessageTextInput"}, "request_timeout": {"trace_as_metadata": true, "list": false, "required": false, "placeholder": "", "show": true, "name": "request_timeout", "value": "", "display_name": "Request Timeout", "advanced": true, "dynamic": false, "info": "", "title_case": false, "type": "float", "_input_type": "FloatInput"}, "show_progress_bar": {"trace_as_metadata": true, "list": false, "required": false, "placeholder": "", "show": true, "name": "show_progress_bar", "value": false, "display_name": "Show Progress Bar", "advanced": true, "dynamic": false, "info": "", "title_case": false, "type": "bool", "_input_type": "BoolInput"}, "skip_empty": {"trace_as_metadata": true, "list": false, "required": false, "placeholder": "", "show": true, "name": "skip_empty", "value": false, "display_name": "Skip Empty", "advanced": true, "dynamic": false, "info": "", "title_case": false, "type": "bool", "_input_type": "BoolInput"}, "tiktoken_enable": {"trace_as_metadata": true, "list": false, "required": false, "placeholder": "", "show": true, "name": "tiktoken_enable", "value": true, "display_name": "TikToken Enable", "advanced": true, "dynamic": false, "info": "If False, you must have transformers installed.", "title_case": false, "type": "bool", "_input_type": "BoolInput"}, "tiktoken_model_name": {"trace_as_input": true, "trace_as_metadata": true, "load_from_db": false, "list": false, "required": false, "placeholder": "", "show": true, "name": "tiktoken_model_name", "value": "", "display_name": "TikToken Model Name", "advanced": true, "input_types": ["Message"], "dynamic": false, "info": "", "title_case": false, "type": "str", "_input_type": "MessageTextInput"}}, "description": "Generate embeddings using OpenAI models.", "icon": "OpenAI", "base_classes": ["Embeddings"], "display_name": "OpenAI Embeddings", "documentation": "", "custom_fields": {}, "output_types": [], "pinned": false, "conditional_paths": [], "frozen": false, "outputs": [{"types": ["Embeddings"], "selected": "Embeddings", "name": "embeddings", "display_name": "Embeddings", "method": "build_embeddings", "value": "__UNDEFINED__", "cache": true}], "field_order": ["default_headers", "default_query", "chunk_size", "client", "deployment", "embedding_ctx_length", "max_retries", "model", "model_kwargs", "openai_api_base", "openai_api_key", "openai_api_type", "openai_api_version", "openai_organization", "openai_proxy", "request_timeout", "show_progress_bar", "skip_empty", "tiktoken_model_name", "tiktoken_enable", "dimensions"], "beta": false, "edited": false}, "id": "OpenAIEmbeddings-iMoBU"}, "selected": false, "width": 384, "height": 388, "positionAbsolute": {"x": 546.0624433564828, "y": 628.7086167740968}, "dragging": false}], "edges": [{"source": "OpenAIEmbeddings-iMoBU", "sourceHandle": "{\u0153dataType\u0153:\u0153OpenAIEmbeddings\u0153,\u0153id\u0153:\u0153OpenAIEmbeddings-iMoBU\u0153,\u0153name\u0153:\u0153embeddings\u0153,\u0153output_types\u0153:[\u0153Embeddings\u0153]}", "target": "AstraDB-xyTk2", "targetHandle": "{\u0153fieldName\u0153:\u0153embedding\u0153,\u0153id\u0153:\u0153AstraDB-xyTk2\u0153,\u0153inputTypes\u0153:[\u0153Embeddings\u0153,\u0153dict\u0153],\u0153type\u0153:\u0153other\u0153}", "data": {"targetHandle": {"fieldName": "embedding", "id": "AstraDB-xyTk2", "inputTypes": ["Embeddings", "dict"], "type": "other"}, "sourceHandle": {"dataType": "OpenAIEmbeddings", "id": "OpenAIEmbeddings-iMoBU", "name": "embeddings", "output_types": ["Embeddings"]}}, "id": "reactflow__edge-OpenAIEmbeddings-iMoBU{\u0153dataType\u0153:\u0153OpenAIEmbeddings\u0153,\u0153id\u0153:\u0153OpenAIEmbeddings-iMoBU\u0153,\u0153name\u0153:\u0153embeddings\u0153,\u0153output_types\u0153:[\u0153Embeddings\u0153]}-AstraDB-xyTk2{\u0153fieldName\u0153:\u0153embedding\u0153,\u0153id\u0153:\u0153AstraDB-xyTk2\u0153,\u0153inputTypes\u0153:[\u0153Embeddings\u0153,\u0153dict\u0153],\u0153type\u0153:\u0153other\u0153}", "className": ""}, {"source": "Directory-jr5lu", "sourceHandle": "{\u0153dataType\u0153:\u0153Directory\u0153,\u0153id\u0153:\u0153Directory-jr5lu\u0153,\u0153name\u0153:\u0153data\u0153,\u0153output_types\u0153:[\u0153Data\u0153]}", "target": "SplitText-zvEyZ", "targetHandle": "{\u0153fieldName\u0153:\u0153data_inputs\u0153,\u0153id\u0153:\u0153SplitText-zvEyZ\u0153,\u0153inputTypes\u0153:[\u0153Data\u0153],\u0153type\u0153:\u0153other\u0153}", "data": {"targetHandle": {"fieldName": "data_inputs", "id": "SplitText-zvEyZ", "inputTypes": ["Data"], "type": "other"}, "sourceHandle": {"dataType": "Directory", "id": "Directory-jr5lu", "name": "data", "output_types": ["Data"]}}, "id": "reactflow__edge-Directory-jr5lu{\u0153dataType\u0153:\u0153Directory\u0153,\u0153id\u0153:\u0153Directory-jr5lu\u0153,\u0153name\u0153:\u0153data\u0153,\u0153output_types\u0153:[\u0153Data\u0153]}-SplitText-zvEyZ{\u0153fieldName\u0153:\u0153data_inputs\u0153,\u0153id\u0153:\u0153SplitText-zvEyZ\u0153,\u0153inputTypes\u0153:[\u0153Data\u0153],\u0153type\u0153:\u0153other\u0153}", "className": ""}, {"source": "SplitText-zvEyZ", "sourceHandle": "{\u0153dataType\u0153:\u0153SplitText\u0153,\u0153id\u0153:\u0153SplitText-zvEyZ\u0153,\u0153name\u0153:\u0153chunks\u0153,\u0153output_types\u0153:[\u0153Data\u0153]}", "target": "AstraDB-xyTk2", "targetHandle": "{\u0153fieldName\u0153:\u0153ingest_data\u0153,\u0153id\u0153:\u0153AstraDB-xyTk2\u0153,\u0153inputTypes\u0153:[\u0153Data\u0153],\u0153type\u0153:\u0153other\u0153}", "data": {"targetHandle": {"fieldName": "ingest_data", "id": "AstraDB-xyTk2", "inputTypes": ["Data"], "type": "other"}, "sourceHandle": {"dataType": "SplitText", "id": "SplitText-zvEyZ", "name": "chunks", "output_types": ["Data"]}}, "id": "reactflow__edge-SplitText-zvEyZ{\u0153dataType\u0153:\u0153SplitText\u0153,\u0153id\u0153:\u0153SplitText-zvEyZ\u0153,\u0153name\u0153:\u0153chunks\u0153,\u0153output_types\u0153:[\u0153Data\u0153]}-AstraDB-xyTk2{\u0153fieldName\u0153:\u0153ingest_data\u0153,\u0153id\u0153:\u0153AstraDB-xyTk2\u0153,\u0153inputTypes\u0153:[\u0153Data\u0153],\u0153type\u0153:\u0153other\u0153}", "className": ""}], "viewport": {"x": 153.08582961652883, "y": 119.78656359484143, "zoom": 0.5661834938270683}}, "user_id": "c8593c1a-7b60-40c2-9dee-4e45e39d3463", "folder_id": "dfd25bb7-888d-45bc-a8fc-b48d533ebc76"}